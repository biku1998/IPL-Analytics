{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"rough_work.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"UiwbEbtfywf-","colab_type":"text"},"source":["### Notebook use:\n","\n","* This notebook will be used to Scrape bating and bowling data from http://stats.espncricinfo.com/ci/engine/records/team/match_results.html?id=2019;trophy=117;type=season\n","\n","* The above link contains a table of match level data and a link to ScoreCard data in the last column .i.e <a> T20 </a>. This link will redirect us to the bating and bowling data page for a particular match e.g. https://www.espncricinfo.com/series/8048/scorecard/1175356/chennai-super-kings-vs-royal-challengers-bangalore-1st-match-indian-premier-league-2019\n","\n","### Approach : \n","\n","* First we have collected all the link of scorecards present in the base url i.e. all the href of <a> T20 </a>.\n","* We will use the func parameter years and no_of_matches to select the year and select the match for scraping the data.\n","\n","* The function will return 2 DataFrames, One will contain all the bating data for n(func param) no of matches and the other will contain all the bowling data for  n(func param) no of matches "]},{"cell_type":"code","metadata":{"id":"EhvppTStywgA","colab_type":"code","colab":{}},"source":["\n","import requests\n","import pandas as pd\n","from bs4 import BeautifulSoup\n","import csv\n","import sys\n","pd.options.display.max_columns = 500\n","pd.options.display.max_rows = 500\n","from tqdm import tqdm_notebook as tqdm"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hR4JYY7KywgE","colab_type":"code","colab":{}},"source":["def fetch_bating_bowling_data(years,no_of_matches=1):\n","    \"\"\" \n","    This Function is used to fetch bating and bowling data from the web.\n","    Parameters\n","    years : a list which contains the years for which you want the data\n","    no_of_matches : no of matches data you want. if -1 is given then it will fetch data of all the matches\n","    return : a tuple of DataFrames, one for bating and one for bowling\n","    \"\"\"\n","    \n","    # a array which will be used to build a complete URL e.g '2019'.join(Base_URL)\n","    Base_URL = [\"http://stats.espncricinfo.com/ci/engine/records/team/match_results.html?id=\",\";trophy=117;type=season\"]\n","    \n","    # check if the passed year is in the format of a list or not and if the list is non-empty\n","    if isinstance(years,list) == False or len(years) == 0:\n","        raise ValueError('Etiher the year is not passed in a list or the list is empty')\n","    \n","    # let's create dataFrames to store data\n","    column_names_bating = ['match_no','match_city','year','month','day','team_1','team_2','batsmen','wicket_status','R',\\\n","                                       'B','M','fours','sixes','SR']\n","    \n","    # let's create a dataFrame with above columns, then we will loop over all the table rows to fill data in it\n","\n","    df_bating_score_card = pd.DataFrame(columns = column_names_bating)\n","\n","    # prepare dataframe for bowling\n","    \n","    column_names_bowling = ['match_no','match_city','year','month','day','team_1','team_2','bowler','O','M',\\\n","                                       'R','W','ECON','zeros','fours','sixes','WD','NB']\n","    # let's create a dataFrame with above columns, then we will loop over all the table rows to fill data in it\n","\n","    df_bowling_score_card = pd.DataFrame(columns = column_names_bowling)\n","\n","    try:\n","\n","\n","\t    # loop for all the years\n","\t    for year in years:\n","\t        # build the URL\n","\t        url = str(year).join(Base_URL)\n","\n","\t        print(f'collecting data for year {year}....')\n","\n","\t        # First we have to parse the batting-bowling data page link from the starter page i.e url\n","\n","\t        # Approach : i will first collect all the links present in that table\n","\t        #            then filter the links which will lead us to bating-bowling data page.\n","\t        # hurdles : in the table a particular row contains 5 links all with same class name.\n","\n","\t        source = requests.get(url).text\n","\n","\t        soup = BeautifulSoup(source, 'lxml') \n","\n","\t        data_table = soup.find('table','engineTable')\n","\n","\t        link_all = data_table.find_all('a','data-link')\n","\n","\t        useful_links = []\n","\t        link_base = \"http://stats.espncricinfo.com\"\n","\n","\t        for link in link_all:\n","\t            href = str(link['href'])\n","\t            if \"/ci/engine/match/\" in href:\n","\t                useful_links.append(link_base+href)\n","\n","\t        \n","\t        # now we have all the links that will lead us to bating and bowling data for a particular year page in useful_links.\n","\t        \n","\t        # now the hard stuff : we have to parse the batting and bowling data page.\n","\n","\t        if no_of_matches == -1:\n","\t            no_of_matches = len(useful_links)\n","\n","\t        for link in tqdm(useful_links[:no_of_matches]):\n","\n","\t            source = requests.get(link).text\n","\n","\t            soup = BeautifulSoup(source, 'lxml')\n","\n","\t            main_div = soup.find('div','col-b')\n","\n","\t            # we will fetch step by step all the data\n","\n","\t            # gp__cricket__gameHeader : it contains the following information ->\n","\t            # 1. match no, match city, match date\n","\t            # 2. team names, their scores,\n","\t            # 3. player of the match with team\n","\t            # 4. a small match summary : Super Kings won by 7 wickets (with 14 balls remaining)\n","\t            \n","\t            div_name = \"gp__cricket__gameHeader\"\n","\t            #################### scrape div_name = \"gp__cricket__gameHeader\" ####################\n","\t            div_gp__cricket__gameHeader_data = main_div.find('div',div_name)\n","\n","\t            # print(div_gp__cricket__gameHeader_data.prettify())\n","\n","\t            match_first_glance_info = div_gp__cricket__gameHeader_data.find('div','cscore_info-overview').text.strip()\n","\t            match_first_glance_info_parts = match_first_glance_info.split(',')\n","\t            \n","\t            match_no = match_first_glance_info_parts[0].split('s')[0] # attribute\n","\n","\t            match_city = match_first_glance_info_parts[1].split('at')[1] # attribute\n","\n","\t            date_parts = match_first_glance_info_parts[2].split(' ')\n","\n","\t            month = date_parts[1] # attribute\n","\t            day = date_parts[2] # attribute\n","\t            year = date_parts[3] # attribute\n","\n","\t            # print(div_gp__cricket__gameHeader_data.prettify())\n","\n","\t            # mom_details = div_gp__cricket__gameHeader_data.find('a','gp__cricket__player-match__player__detail__link').contents\n","\t            \n","\t            # mom_player_name = mom_details[0].strip() # attribute\n","\t            # mom_team_name = mom_details[1].text.strip() # attribute\n","\n","\t            teams = div_gp__cricket__gameHeader_data.find_all('span','cscore_name cscore_name--long')\n","\t            team_1 = teams[0].text.strip() # attribute\n","\t            team_2 = teams[1].text.strip() # attribute\n","\n","\n","\t            \n","\n","\t            ###############################################################################################\n","\n","\t            ############# Now we will Scrape ScoreCards i.e bating and bowling performance for each team #######################\n","\n","\n","\t            score_cards = main_div.find_all('article','sub-module scorecard')\n","\n","\t            # above score_cards contain 2 score_card i.e. each team\n","                \n","\t            for score_card in score_cards:\n","\n","\t                batsmen_div = score_card.find('div','scorecard-section batsmen')\n","\n","\t                # print(batsmen_div.prettify()) # for debug\n","\n","\t                if batsmen_div is None:\n","\t                \tcontinue\n","\n","\t                # fetching all batsman \n","\t                for one in batsmen_div.find_all('div','wrap batsmen'):\n","\t                        # one = batsmen_div.find('div','wrap batsmen')\n","\n","\t                        if one  is None:\n","\t                        \tcontinue\n","\n","\n","\t                        batsmen = one.find('div','cell batsmen').text.strip()\n","\n","\t                        # wicket_status = one.find_all('div','cell commentary')[0].find('a').contents[0].strip()\n","\t                        try:\n","\t                            wicket_status = one.find_all('div','cell commentary')[0].contents[0].text.strip()\n","\t                        except Exception as e:\n","\t                            wicket_status = one.find_all('div','cell commentary')[0].contents[0].strip()\n","\t                        \n","\t                        # print(one.find_all('div','cell commentary')[0].contents[0].text.strip())\n","\n","\n","\t                        all_numeric  = one.find_all('div','cell runs')\n","\t                        # print(len(all_numeric))\n","\n","\t                        R = ''\n","\t                        B = ''\n","\t                        M = ''\n","\t                        fours = ''\n","\t                        sixes = '' \n","\t                        SR = ''\n","\t                        info = [R,B,M,fours,sixes,SR]\n","\n","\t                        if len(all_numeric) == 5:\n","\t                            all_numeric.insert(2,'')\n","\t                        # print(len(list(map(lambda x : x.text,all_numeric))))\n","\t                        # print(list(map(lambda x : x.text,all_numeric)))\n","\t                        for i,n in enumerate(all_numeric):\n","\t                            # print(n.text.strip())\n","\t                            if i < len(info):\n","\t                                if isinstance(n,str):\n","\t                                    info[i] = info[i]+n\n","\t                                else:\n","\t                                    info[i] = info[i]+n.text.strip()\n","\t                            \n","\n","\t                        # print(date_parts)\n","\t                        df_bating_score_card = df_bating_score_card.append({'match_no': match_no, 'match_city': match_city,'year': year, \\\n","\t                                                    'month': month,'day': day,'team_1':team_1,'team_2':team_2,'batsmen':batsmen,\n","\t                                                    'wicket_status':wicket_status,'R':info[0],'B':info[1],'M':info[2],\n","\t                                                    'fours':info[3],'sixes':info[4],\n","\t                                                    'SR':info[5]\n","\t                                                    }, ignore_index=True)\n","\t                        \n","\n","\t                # we will follow the similar approach to fetch all the bowlers for both innings\n","\n","\t                # bowling_div = score_card.find_all('div','scorecard-section bowling')\n","\t                bowling_all =  score_card.find_all('div','scorecard-section bowling')\n","\t                # print(len(bowling_all))\n","\t                # print(bowling_all.prettify())\n","\n","\t                if bowling_all is None:\n","\t                \tcontinue\n","\t                for bowling_div in bowling_all:\n","\t                        # print(bowling_div.prettify())\n","\t                        all_rows = []\n","\t                        bowling_table_data = bowling_div.find('table').find_all('tr')\n","\t                        for tr in bowling_table_data:\n","\t                            td = tr.find_all('td')\n","\t                            row = [tr.text.strip() for tr in td]\n","\t                            all_rows.append(row)\n","\t                        \n","\t                        for data_row in all_rows:\n","\t                            if len(data_row) != 0:\n","\t                                df_bowling_score_card = df_bowling_score_card.append({'match_no': match_no, 'match_city': match_city,'year': year, \\\n","\t                                                                'month': month,'day': day,'team_1':team_1,'team_2':team_2,'bowler':data_row[0],\n","\t                                                                'O':data_row[2],'M':data_row[3],'R':data_row[4],'W':data_row[5],'ECON':data_row[6],\n","\t                                                                'zeros':data_row[7],\n","\t                                                                'fours':data_row[8],'sixes':data_row[9],\n","\t                                                                'WD':data_row[10],'NB':data_row[11]\n","\t                                                                }, ignore_index=True)\n","\n","\t    return df_bating_score_card,df_bowling_score_card\n","\n","    except Exception as e:\n","    \tprint(e)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P8mtzEQfywgG","colab_type":"code","colab":{}},"source":["year_list = [2018]\n","(df_bat,df_bowl) = fetch_bating_bowling_data(year_list,no_of_matches = -1)"],"execution_count":0,"outputs":[]}]}